{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdd81ac-36e5-4b6e-85df-daca03751e25",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f4afff-8bcb-402d-870b-fa94bcdd84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 21:03:07.471367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-06 21:03:07.471387: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-06 21:03:07.477567: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-06 21:03:08.334834: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, TextVectorization, Embedding, Dense, Activation, LSTM, Conv1D, GlobalAveragePooling1D, BatchNormalization, Dropout\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200f6c0-cf26-46ac-8a51-97eaa5cea26b",
   "metadata": {},
   "source": [
    "## Getting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b825ff-8539-4d8a-835e-e6c3b7fc9301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = pd.read_json('Cell_Phones_and_Accessories_5.json', lines = True)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcaedae-0117-4028-b98e-892ff9fb3b90",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbfb79a-5bba-409f-96cc-0e02f82923f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName      3519\n",
       "helpful              0\n",
       "reviewText           0\n",
       "overall              0\n",
       "summary              0\n",
       "unixReviewTime       0\n",
       "reviewTime           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd64ac2-1344-4ab9-90d2-b464f1a684e9",
   "metadata": {},
   "source": [
    "Dropping reviewerName as it has null values and it is not important to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1554e5-ccca-4a23-9e4d-460680ed3e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = review_data.drop(['reviewerName'], axis =1)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819de4bf-0c09-4d1a-aa38-dc3ba9be632e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5    108664\n",
       "4     39993\n",
       "3     21439\n",
       "1     13279\n",
       "2     11064\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467a154b-16c4-49dd-a86f-7522874d17cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='overall', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data = review_data, x = 'overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67d987-99dc-4b60-8a99-b4d5fd9ffe5a",
   "metadata": {},
   "source": [
    "## Keeping reviewText and overall columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07a1e57-25d0-439a-94ff-1e5597845170",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = review_data['reviewText']\n",
    "labels = review_data['overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd006207-27f1-4dc4-b0d2-cc3bc0243642",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f67d1c-d4a3-45b4-bb97-fe0ef061d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0140721-6036-456c-9ced-8ca7ec1a13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size = 0.3, random_state =42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950947ff-26dc-423c-b0fd-55d41d0a2f02",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30c03361-2d3b-441d-be7b-5de33123c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output = False)\n",
    "train_labels_onehot = one_hot_encoder.fit_transform(y_train.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcaa5d2f-678d-4c2d-923c-318857027256",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_onehot = one_hot_encoder.transform(y_test.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e915f98-7050-42a0-91e2-79ba9db84cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037710a-8e43-4ae0-bb11-8c1f79f38ecb",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b26a8c-83f5-42ae-8436-7276d1034894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50cfd20-cfb8-4f36-ab31-668074d9fd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = make_pipeline(\n",
    "    (TfidfVectorizer()),\n",
    "    (MultinomialNB())\n",
    ")\n",
    "\n",
    "baseline_model.fit(X = X_train,\n",
    "                   y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5247248d-5bec-428c-a10e-c0add7377f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f1cd4e-bad3-4d1c-b98c-08ee97f1af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(y_true, y_preds):\n",
    "    '''\n",
    "    Gives the accuracy, recall, precision and f1-score in a dictionary format\n",
    "\n",
    "    Args:\n",
    "         y_true: Actual values i.e label\n",
    "         y_pred: Predictions given by the model\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing Accuracy, Recall, Precision, F1-score\n",
    "    '''\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision, recall, f1_score , _ = precision_recall_fscore_support(y_true,y_preds, average= 'weighted')\n",
    "    \n",
    "    results = {'Accuracy':accuracy,\n",
    "               'Recall':recall,\n",
    "               'Precision':precision,\n",
    "               'F1-score':f1_score}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef80c048-4538-4d93-beda-9b05d91d5e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_predict = baseline_model.predict(X_test)\n",
    "baseline_model_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11fd1425-bd1d-452e-9a00-72c17b445549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5595042172392511,\n",
       " 'Recall': 0.5595042172392511,\n",
       " 'Precision': 0.5021230020453383,\n",
       " 'F1-score': 0.4025129432806949}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselin_results = calculate_results(y_true = y_test, y_preds=baseline_model_predict)\n",
    "baselin_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8adf5-7ac0-4eda-bc77-36529e4fb6de",
   "metadata": {},
   "source": [
    "## Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef89aed-1875-4b1e-93e8-19926cc15bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 21:03:41.997715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660 Ti, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 21:03:42.445606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:42.445757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:42.446974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f769b8d-2b71-4303-ab9e-1f8c95856c1f",
   "metadata": {},
   "source": [
    "## Tokenising and Embedding the Training data and OneHotEncoding Training Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac99da-532c-462f-a4a7-1c7220abe516",
   "metadata": {},
   "source": [
    "### Tokenizing and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ba62ec-05cc-49b6-85d8-5d75f0cca354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence_length = [len(sentence.split()) for sentence in X_train]\n",
    "# sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03d7307c-5251-40e1-8ebd-97d5cde1f810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequence_length = int(np.percentile(sequence_length,95))\n",
    "output_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3baf07e1-9bd4-459a-a430-4c9f315c02fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 21:03:43.195254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.195422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.195512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.425381: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.425496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.425591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 21:03:43.425669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4657 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TextVectorization(max_tokens = None,\n",
    "                            standardize = 'lower_and_strip_punctuation',\n",
    "                            split = 'whitespace',\n",
    "                            output_sequence_length = output_sequence_length\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47b7c7d6-5e7d-4f7d-867a-6e9398bc7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a611629-0931-4e61-ba4c-fdd9f29f1ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top five words['', '[UNK]', 'the', 'i', 'and'] \n",
      "Bottom five['00005', '00002', '000000', '00000', '\\x1d\\x1dwhile']\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocabulary()\n",
    "print(f'Top five words{vocab[:5]} \\nBottom five{vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8102f0c0-2117-4daf-94fb-463e4700fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim = len(vocab),\n",
    "                       output_dim = 512,\n",
    "                       input_length = output_sequence_length,\n",
    "                        mask_zero = True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f003f-28ca-4dfd-a366-5031f2cc230e",
   "metadata": {},
   "source": [
    "## Creating a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52a8847a-992d-4983-9f43-46eaea45e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, train_labels_onehot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, test_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "277c2378-a6e9-4105-b1a5-ba6f5e65a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2981d-1063-4ef3-9f29-1033311b5d4c",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93608e9-2761-48ef-9fa3-e16f5050d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoint(name):\n",
    "    # filepath = 'checkpoints/{}.ckpt'.format(name)\n",
    "    filepath = 'checkpoints/'+ name + '.ckpt'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = filepath,\n",
    "                                                    monitor = 'val_accuracy',\n",
    "                                                    save_weights_only = True,\n",
    "                                                    save_best_only = True,\n",
    "                                                    save_freq = 'epoch',\n",
    "                                                    verbose = 1\n",
    "                                                   )\n",
    "    return checkpoint\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                 verbose =1,\n",
    "                                                 patience = 3)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                                verbose = 1,\n",
    "                                                factor = 0.2,\n",
    "                                                min_lr = 1e-7,\n",
    "                                                patience = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df821c9b-fcc5-493a-9e5b-50b74a31b81a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a8469f5-1915-433a-9fc7-edd5c3460c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=[1,], dtype = tf.string, name = 'input_layer')\n",
    "\n",
    "x = tokenizer(inputs)\n",
    "x = embedding_layer(x)\n",
    "\n",
    "x = LSTM(64, return_sequences = True)(x)\n",
    "x = LSTM(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "\n",
    "outputs = Dense(5, activation = 'softmax', dtype = tf.float32)(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "122f62d1-92bc-4526-81ba-cf8c424ac960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "             optimizer = tf.keras.optimizers.Adam(),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c76785d-c3f5-4ca1-8367-d2d7503eeb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4253/4254 [============================>.] - ETA: 0s - loss: 1.1062 - accuracy: 0.6158\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64057, saving model to checkpoints/model.ckpt\n",
      "4254/4254 [==============================] - 288s 66ms/step - loss: 1.1062 - accuracy: 0.6158 - val_loss: 1.0480 - val_accuracy: 0.6406 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.9890 - accuracy: 0.6766\n",
      "Epoch 2: val_accuracy improved from 0.64057 to 0.66629, saving model to checkpoints/model.ckpt\n",
      "4254/4254 [==============================] - 249s 59ms/step - loss: 0.9890 - accuracy: 0.6766 - val_loss: 1.0053 - val_accuracy: 0.6663 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4253/4254 [============================>.] - ETA: 0s - loss: 0.8706 - accuracy: 0.7459\n",
      "Epoch 3: val_accuracy did not improve from 0.66629\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "4254/4254 [==============================] - 243s 57ms/step - loss: 0.8705 - accuracy: 0.7459 - val_loss: 1.0491 - val_accuracy: 0.6565 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4253/4254 [============================>.] - ETA: 0s - loss: 0.7219 - accuracy: 0.8307\n",
      "Epoch 4: val_accuracy did not improve from 0.66629\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "4254/4254 [==============================] - 245s 58ms/step - loss: 0.7219 - accuracy: 0.8307 - val_loss: 1.1189 - val_accuracy: 0.6474 - lr: 2.0000e-04\n",
      "Epoch 5/100\n",
      "4253/4254 [============================>.] - ETA: 0s - loss: 0.6595 - accuracy: 0.8680\n",
      "Epoch 5: val_accuracy did not improve from 0.66629\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "4254/4254 [==============================] - 244s 57ms/step - loss: 0.6594 - accuracy: 0.8681 - val_loss: 1.1540 - val_accuracy: 0.6497 - lr: 4.0000e-05\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_dataset,\n",
    "                         epochs = 100,\n",
    "                         validation_data = test_dataset,\n",
    "                         validation_steps = len(test_dataset),\n",
    "                         callbacks = [create_checkpoint('model'),\n",
    "                                     early_stopping,\n",
    "                                     reduce_lr]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afa8e384-fbd7-46b4-982e-764f53dc45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=[1,], dtype = tf.string, name = 'input_layer')\n",
    "\n",
    "x = tokenizer(inputs)\n",
    "x = embedding_layer(x)\n",
    "\n",
    "x = LSTM(64, return_sequences = True)(x)\n",
    "x = LSTM(32)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(16, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(5, activation = 'softmax',dtype = tf.float32)(x)\n",
    "\n",
    "model2 = tf.keras.models.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ab706be-e1b9-4a50-824f-5273b4ee863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "             optimizer = tf.keras.optimizers.Adam(),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "154af0bb-86a1-4ef3-87f3-399758ee733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.8795 - accuracy: 0.7504\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62724, saving model to checkpoints/model2.ckpt\n",
      "4254/4254 [==============================] - 308s 71ms/step - loss: 0.8795 - accuracy: 0.7504 - val_loss: 1.1322 - val_accuracy: 0.6272 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.8169\n",
      "Epoch 2: val_accuracy improved from 0.62724 to 0.64335, saving model to checkpoints/model2.ckpt\n",
      "4254/4254 [==============================] - 254s 60ms/step - loss: 0.7546 - accuracy: 0.8169 - val_loss: 1.1277 - val_accuracy: 0.6434 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.8517\n",
      "Epoch 3: val_accuracy did not improve from 0.64335\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "4254/4254 [==============================] - 246s 58ms/step - loss: 0.6894 - accuracy: 0.8517 - val_loss: 1.1578 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.8994\n",
      "Epoch 4: val_accuracy did not improve from 0.64335\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "4254/4254 [==============================] - 246s 58ms/step - loss: 0.6028 - accuracy: 0.8994 - val_loss: 1.2295 - val_accuracy: 0.6384 - lr: 2.0000e-04\n",
      "Epoch 5/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.9288\n",
      "Epoch 5: val_accuracy did not improve from 0.64335\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "4254/4254 [==============================] - 246s 58ms/step - loss: 0.5513 - accuracy: 0.9288 - val_loss: 1.2734 - val_accuracy: 0.6320 - lr: 4.0000e-05\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "model2_history = model2.fit(train_dataset,\n",
    "                         epochs = 100,\n",
    "                         validation_data = test_dataset,\n",
    "                         validation_steps = len(test_dataset),\n",
    "                         callbacks = [create_checkpoint('model2'),\n",
    "                                     early_stopping,\n",
    "                                     reduce_lr]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649b082-2825-4ae3-aee7-33c150b2eca6",
   "metadata": {},
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54120d6f-a1ef-4ff5-be6c-63fbd67b6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc2efa-53c0-46a2-a55e-0f8f03fb2e12",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b175d511-e154-4daa-b00f-99b147a3a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_bert = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "test_dataset_bert = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f695a9d9-dd23-4a4e-a655-5cde3cae8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_bert = train_dataset_bert.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset_bert  = test_dataset_bert.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06866049-790b-410f-b0e8-23bc9e3b2cfc",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bf7b487-02de-48a4-a573-a83fadd76971",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_url = \"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\"\n",
    "# encoder_url = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-256-a-4/versions/2\"\n",
    "encoder_url =     \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-10-h-128-a-2/versions/2\"\n",
    "preprocessor = hub.KerasLayer(preprocessor_url)\n",
    "\n",
    "encoder = hub.KerasLayer(encoder_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8435684-e10f-4b59-a61f-d41669de3a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)    {'input_word_ids': (None,    0         ['input_1[0][0]']             \n",
      "                             128),                                                                \n",
      "                              'input_type_ids': (None,                                            \n",
      "                             128),                                                                \n",
      "                              'input_mask': (None, 128)                                           \n",
      "                             }                                                                    \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)  {'default': (None, 128),     5972097   ['keras_layer[0][0]',         \n",
      "                              'sequence_output': (None,              'keras_layer[0][1]',         \n",
      "                              128, 128),                             'keras_layer[0][2]']         \n",
      "                              'encoder_outputs': [(None                                           \n",
      "                             , 128, 128),                                                         \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128)],                                                  \n",
      "                              'pooled_output': (None, 1                                           \n",
      "                             28)}                                                                 \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 10)                   1290      ['keras_layer_1[0][11]']      \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 5)                    55        ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5973442 (22.79 MB)\n",
      "Trainable params: 5973441 (22.79 MB)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (), dtype = tf.string)\n",
    "x = preprocessor(inputs)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x['pooled_output'])\n",
    "outputs = tf.keras.layers.Dense(5, activation = 'softmax',dtype = tf.float32)(x)\n",
    "\n",
    "bert = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "bert.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "             metrics = ['accuracy']\n",
    "             )\n",
    "\n",
    "bert.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3fb5c33-1153-44eb-8978-556e544f98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.5934\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62260, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 474s 107ms/step - loss: 1.0158 - accuracy: 0.5934 - val_loss: 0.9277 - val_accuracy: 0.6226 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.9041 - accuracy: 0.6367\n",
      "Epoch 2: val_accuracy improved from 0.62260 to 0.64320, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 441s 104ms/step - loss: 0.9041 - accuracy: 0.6367 - val_loss: 0.8858 - val_accuracy: 0.6432 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.8652 - accuracy: 0.6514\n",
      "Epoch 3: val_accuracy improved from 0.64320 to 0.65007, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 445s 105ms/step - loss: 0.8652 - accuracy: 0.6514 - val_loss: 0.8667 - val_accuracy: 0.6501 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.6610\n",
      "Epoch 4: val_accuracy improved from 0.65007 to 0.65110, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 446s 105ms/step - loss: 0.8383 - accuracy: 0.6610 - val_loss: 0.8505 - val_accuracy: 0.6511 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.8183 - accuracy: 0.6698\n",
      "Epoch 5: val_accuracy did not improve from 0.65110\n",
      "4254/4254 [==============================] - 446s 105ms/step - loss: 0.8183 - accuracy: 0.6698 - val_loss: 0.8386 - val_accuracy: 0.6508 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.6743\n",
      "Epoch 6: val_accuracy improved from 0.65110 to 0.66037, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 448s 105ms/step - loss: 0.8019 - accuracy: 0.6743 - val_loss: 0.8353 - val_accuracy: 0.6604 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7876 - accuracy: 0.6802\n",
      "Epoch 7: val_accuracy did not improve from 0.66037\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "4254/4254 [==============================] - 447s 105ms/step - loss: 0.7876 - accuracy: 0.6802 - val_loss: 0.8377 - val_accuracy: 0.6511 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7689 - accuracy: 0.6879\n",
      "Epoch 8: val_accuracy improved from 0.66037 to 0.66277, saving model to checkpoints/bert_model.ckpt\n",
      "4254/4254 [==============================] - 447s 105ms/step - loss: 0.7689 - accuracy: 0.6879 - val_loss: 0.8281 - val_accuracy: 0.6628 - lr: 2.0000e-06\n",
      "Epoch 9/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.6905\n",
      "Epoch 9: val_accuracy did not improve from 0.66277\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "4254/4254 [==============================] - 445s 105ms/step - loss: 0.7646 - accuracy: 0.6905 - val_loss: 0.8298 - val_accuracy: 0.6604 - lr: 2.0000e-06\n",
      "Epoch 10/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7613 - accuracy: 0.6914\n",
      "Epoch 10: val_accuracy did not improve from 0.66277\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "4254/4254 [==============================] - 444s 104ms/step - loss: 0.7613 - accuracy: 0.6914 - val_loss: 0.8291 - val_accuracy: 0.6617 - lr: 4.0000e-07\n",
      "Epoch 11/100\n",
      "4254/4254 [==============================] - ETA: 0s - loss: 0.7601 - accuracy: 0.6916\n",
      "Epoch 11: val_accuracy did not improve from 0.66277\n",
      "4254/4254 [==============================] - 442s 104ms/step - loss: 0.7601 - accuracy: 0.6916 - val_loss: 0.8294 - val_accuracy: 0.6600 - lr: 1.0000e-07\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa2a435fd30>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.fit(train_dataset,\n",
    "         steps_per_epoch = int(len(train_dataset)),\n",
    "         epochs = 100,\n",
    "         validation_data=test_dataset,\n",
    "         validation_steps =int(0.05*len(test_dataset)),\n",
    "         callbacks = [create_checkpoint('bert_model'),\n",
    "                                     early_stopping,\n",
    "                                     reduce_lr]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe3537-1fae-4f26-9ae5-2f0fadde5767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4cebbab-c995-425f-b41c-72bac8625612",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_url = \"https://kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3\"\n",
    "# encoder_url = \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-256-a-4/versions/2\"\n",
    "encoder_url =     \"https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-10-h-128-a-2/versions/2\"\n",
    "preprocessor = hub.KerasLayer(preprocessor_url)\n",
    "\n",
    "encoder = hub.KerasLayer(encoder_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "079b655c-9280-40c0-b2b7-37c8d221f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " keras_layer_6 (KerasLayer)  {'input_mask': (None, 128)   0         ['input_5[0][0]']             \n",
      "                             , 'input_type_ids': (None,                                           \n",
      "                              128),                                                               \n",
      "                              'input_word_ids': (None,                                            \n",
      "                             128)}                                                                \n",
      "                                                                                                  \n",
      " keras_layer_7 (KerasLayer)  {'pooled_output': (None, 1   5972097   ['keras_layer_6[0][0]',       \n",
      "                             28),                                    'keras_layer_6[0][1]',       \n",
      "                              'encoder_outputs': [(None              'keras_layer_6[0][2]']       \n",
      "                             , 128, 128),                                                         \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128),                                                   \n",
      "                              (None, 128, 128)],                                                  \n",
      "                              'default': (None, 128),                                             \n",
      "                              'sequence_output': (None,                                           \n",
      "                              128, 128)}                                                          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 10)                   1290      ['keras_layer_7[0][11]']      \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 5)                    55        ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5973442 (22.79 MB)\n",
      "Trainable params: 5973441 (22.79 MB)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (), dtype = tf.string)\n",
    "x = preprocessor(inputs)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x['pooled_output'])\n",
    "outputs = tf.keras.layers.Dense(5, activation = 'softmax',dtype = tf.float32)(x)\n",
    "\n",
    "bert2 = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "bert2.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "             metrics = ['accuracy']\n",
    "             )\n",
    "\n",
    "bert2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20df52b3-cbb9-48f6-b1dd-5c4c3df535f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "425/425 [==============================] - ETA: 0s - loss: 1.3767 - accuracy: 0.2234\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22390, saving model to checkpoints/bert2_model.ckpt\n",
      "425/425 [==============================] - 98s 165ms/step - loss: 1.3767 - accuracy: 0.2234 - val_loss: 1.3257 - val_accuracy: 0.2239 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "214/425 [==============>...............] - ETA: 22s - loss: 1.2621 - accuracy: 0.3518"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbert2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcreate_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert2_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Mayank/PycharmProjects/TF_GPU/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert2.fit(train_dataset,\n",
    "         steps_per_epoch = int(0.1*len(train_dataset)),\n",
    "         epochs = 100,\n",
    "         validation_data=test_dataset,\n",
    "         validation_steps =int(0.05*len(test_dataset)),\n",
    "         callbacks = [create_checkpoint('bert2_model'),\n",
    "                                     early_stopping,\n",
    "                                     reduce_lr]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0698fa5-42ae-4872-950a-39f84f797571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
